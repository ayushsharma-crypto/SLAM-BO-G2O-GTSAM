{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "from sys import argv, exit\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import copy\n",
    "import os\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Cube vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVertices():\n",
    "    points = [[0, 8, 8], [0, 0, 8], [0, 0, 0], [0, 8, 0], [8, 8, 8], [8, 0, 8], [8, 0, 0], [8, 8, 0]]\n",
    "\n",
    "    vertices = []\n",
    "\n",
    "    for ele in points:\n",
    "        if(ele is not None):\n",
    "            sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.2)\n",
    "            sphere.paint_uniform_color([0.9, 0.2, 0])\n",
    "\n",
    "            trans = np.identity(4)\n",
    "            trans[0, 3] = ele[0]\n",
    "            trans[1, 3] = ele[1]\n",
    "            trans[2, 3] = ele[2]\n",
    "\n",
    "            sphere.transform(trans)\n",
    "            vertices.append(sphere)\n",
    "\n",
    "    return vertices, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices, points = getVertices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Robot positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrames():\n",
    "    # posei = ( x, y, z, thetaZ(deg) )\n",
    "\n",
    "    poses = [[-12, 0, 0, 0], [-10, -4, 0, 30], [-8, -8, 0, 60], [-4, -12, 0, 75], [0, -16, 0, 80]]\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for pose in poses:\n",
    "        T = np.identity(4)\n",
    "        T[0, 3], T[1, 3], T[2, 3] = pose[0], pose[1], pose[2]\n",
    "        T[0:3, 0:3] = R.from_euler('z', pose[3], degrees=True).as_matrix()\n",
    "\n",
    "        frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1.2, origin=[0, 0, 0])\n",
    "        frame.transform(T)\n",
    "        frames.append(frame)\n",
    "\n",
    "    return frames, poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, poses = getFrames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Ground Truth robot positions and cube vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeData(vertices, frames):\n",
    "    geometries = []\n",
    "    geometries = geometries + vertices + frames\n",
    "\n",
    "    o3d.visualization.draw_geometries(geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeData(vertices, frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating cube as a local point cloud viewed from five different robot's positions.  \n",
    "Adding noise in measurement of cube vertices in local frame from robot's five different positions to simulate inaccuracy in depth calculation in real sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocalCubes(points, poses):\n",
    "    # Returns local point cloud cubes\n",
    "\n",
    "    points = np.array(points)\n",
    "    poses = np.array(poses)\n",
    "\n",
    "    nPoses, nPoints, pointDim = poses.shape[0], points.shape[0], points.shape[1]\n",
    "    cubes = np.zeros((nPoses, nPoints, pointDim))\n",
    "\n",
    "    for i, pose in enumerate(poses):\n",
    "        cube = []\n",
    "\n",
    "        T = np.identity(4)\n",
    "        T[0, 3], T[1, 3], T[2, 3] = pose[0], pose[1], pose[2]\n",
    "        T[0:3, 0:3] = R.from_euler('z', pose[3], degrees=True).as_matrix()\n",
    "\n",
    "        for pt in np.hstack((points, np.ones((points.shape[0], 1)))):\n",
    "            ptLocal = np.linalg.inv(T) @ pt.reshape(4, 1)\n",
    "\n",
    "            cube.append(ptLocal.squeeze(1)[0:3])\n",
    "\n",
    "        cubes[i] = np.asarray(cube)\n",
    "\n",
    "    return cubes\n",
    "\n",
    "\n",
    "def addNoiseCubes(cubes, noise=0):\n",
    "    noisyCubes = np.zeros(cubes.shape)\n",
    "\n",
    "    for i in range(cubes.shape[0]):\n",
    "        noiseMat = np.random.normal(0, noise, cubes[i].size).reshape(cubes[i].shape)\n",
    "        noisyCubes[i] = cubes[i] + noiseMat\n",
    "\n",
    "    return noisyCubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtCubes = getLocalCubes(points, poses)\n",
    "noisyCubesHigh = addNoiseCubes(gtCubes, noise=2.0)\n",
    "noisyCubesLow = addNoiseCubes(gtCubes, noise=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Task\n",
    "\n",
    "Now from above, we have local observations of the 8 points of the point cloud from every pose. Now the question is, if we optimize these redundant measurements, will we get close to ground truth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying ICP to calculate the relative transformations between robot poses for odometry constraints in Pose Graph Optimization.  \n",
    "ICP is initialized using known correspondences, so we would get a close form solution in step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icpTransformations(cubes):\n",
    "    # T1_2 : 2 wrt 1 \n",
    "\n",
    "    P1 = cubes[0]\n",
    "    P2 = cubes[1]\n",
    "    P3 = cubes[2]\n",
    "    P4 = cubes[3]\n",
    "    P5 = cubes[4]\n",
    "\n",
    "    pcd1, pcd2, pcd3, pcd4, pcd5 = (o3d.geometry.PointCloud(), o3d.geometry.PointCloud(), \n",
    "    o3d.geometry.PointCloud(), o3d.geometry.PointCloud(), o3d.geometry.PointCloud())\n",
    "\n",
    "    pcd1.points = o3d.utility.Vector3dVector(P1)\n",
    "    pcd2.points = o3d.utility.Vector3dVector(P2)\n",
    "    pcd3.points = o3d.utility.Vector3dVector(P3)\n",
    "    pcd4.points = o3d.utility.Vector3dVector(P4)\n",
    "    pcd5.points = o3d.utility.Vector3dVector(P5)\n",
    "\n",
    "    corr = np.array([(i, i) for i in range(8)]) \n",
    "\n",
    "    p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "\n",
    "    T1_2 = p2p.compute_transformation(pcd2, pcd1, o3d.utility.Vector2iVector(corr))\n",
    "    T2_3 = p2p.compute_transformation(pcd3, pcd2, o3d.utility.Vector2iVector(corr))\n",
    "    T3_4 = p2p.compute_transformation(pcd4, pcd3, o3d.utility.Vector2iVector(corr))\n",
    "    T4_5 = p2p.compute_transformation(pcd5, pcd4, o3d.utility.Vector2iVector(corr))\n",
    "\n",
    "    draw_registration_result(pcd2, pcd1, T1_2)\n",
    "\n",
    "    trans = np.array([T1_2, T2_3, T3_4, T4_5])\n",
    "\n",
    "    return trans\n",
    "\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(source_temp)\n",
    "    vis.add_geometry(target_temp)\n",
    "    vis.get_render_option().point_size = 15\n",
    "    vis.run()\n",
    "    vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registering two point clouds using transformation obtained using ICP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = icpTransformations(noisyCubesHigh)\n",
    "# Here by giving `noisyCubesHigh`, we are just saying our relative poses are very noisy. \n",
    "# Do not worry about how we are obtaining it (ICP), just think of it as some noisy odometry\n",
    "# sensor giving consecutive relative poses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the quality of ICP transformations by projecting all local point clouds to the first robot's frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def registerCubes(trans, cubes):\n",
    "    # Registering noisy cubes in first frame\n",
    "\n",
    "    cloud1 = getCloud(cubes[0], [0.9, 0.2, 0])\n",
    "    cloud2 = getCloud(cubes[1], [0, 0.2, 0.9])\n",
    "    cloud3 = getCloud(cubes[2], [0.2, 0.9, 0])\n",
    "    cloud4 = getCloud(cubes[3], [0.5, 0, 0.95])\n",
    "    cloud5 = getCloud(cubes[4], [0.9, 0.45, 0])\n",
    "\n",
    "    T1_2 = trans[0]\n",
    "    T2_3 = trans[1]\n",
    "    T3_4 = trans[2]\n",
    "    T4_5 = trans[3]\n",
    "\n",
    "    cloud2 = [ele.transform(T1_2) for ele in cloud2]\n",
    "    cloud3 = [ele.transform(T1_2 @ T2_3) for ele in cloud3]\n",
    "    cloud4 = [ele.transform(T1_2 @ T2_3 @ T3_4) for ele in cloud4]\n",
    "    cloud5 = [ele.transform(T1_2 @ T2_3 @ T3_4 @ T4_5) for ele in cloud5]\n",
    "\n",
    "    geometries = cloud1 + cloud2 + cloud3 + cloud4 + cloud5\n",
    "\n",
    "    o3d.visualization.draw_geometries(geometries)\n",
    "\n",
    "\n",
    "def getCloud(cube, color):\n",
    "    vertices = []\n",
    "\n",
    "    for ele in cube:\n",
    "        sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.15)\n",
    "        sphere.paint_uniform_color(color)\n",
    "\n",
    "        trans = np.identity(4)\n",
    "        trans[0, 3] = ele[0]\n",
    "        trans[1, 3] = ele[1]\n",
    "        trans[2, 3] = ele[2]\n",
    "\n",
    "        sphere.transform(trans)\n",
    "        vertices.append(sphere)\n",
    "\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to noise in the sensor measurements, vertices are not overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "registerCubes(trans, noisyCubesLow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating G2O file for pose graph optimization.  \n",
    "Robot poses are the form of `VERTEX_SE3:QUAT`, because our landmarks are in 3D. Poses are caculated  using ICP.  \n",
    "`VERTEX_SE3:QUAT i x y z q_x q_y q_z q_w`  \n",
    "Odometry edges are of the form `EDGE_SE3:QUAT`.  \n",
    "`EDGE_SE3:QUAT i j x y z q_x q_y q_z q_w info(x, y, z, theta_x, theta_y, theta_z)`  \n",
    "Cube vertices are of the form of `VERTEX_SE3:QUAT`. Cube vertices are intialized with respect to first frame.  \n",
    "Landmark edges are of the form of `EDGE_SE3:QUAT`. Each landmark edge connects a robot position with the 8 cube vertices. So, we have `5x8=40` landmark edges.   \n",
    "Information matrix for odometry edges, $\\omega_{odom}$ = `20 0 0 0 0 0 20 0 0 0 0 20 0 0 0 20 0 0 20 0 20`   \n",
    "Information matrix for landmark to robot edges, $\\omega_{landmark}$ = `40 0 0 0 0 0 40 0 0 0 0 40 0 0 0 0.000001 0 0 0.000001 0 0.000001`  \n",
    "![landmark_edges.png](attachment:landmark_edges.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeRobotPose(trans, g2o):\n",
    "    # Tw_1: 1 wrt w\n",
    "\n",
    "    start = [-12, 0, 0, 0]\n",
    "\n",
    "    Tw_1 = np.identity(4)\n",
    "    Tw_1[0, 3], Tw_1[1, 3], Tw_1[2, 3] = start[0], start[1], start[2]\n",
    "    Tw_1[0:3, 0:3] = R.from_euler('z', start[3], degrees=True).as_matrix()\n",
    "\n",
    "    T1_2, T2_3, T3_4, T4_5 = trans[0], trans[1], trans[2], trans[3]\n",
    "\n",
    "    Tw_2 = Tw_1 @ T1_2\n",
    "    Tw_3 = Tw_2 @ T2_3\n",
    "    Tw_4 = Tw_3 @ T3_4\n",
    "    Tw_5 = Tw_4 @ T4_5\n",
    "\n",
    "    pose1 = [Tw_1[0, 3], Tw_1[1, 3], Tw_1[2, 3]] + list(R.from_matrix(Tw_1[0:3, 0:3]).as_quat())\n",
    "    pose2 = [Tw_2[0, 3], Tw_2[1, 3], Tw_2[2, 3]] + list(R.from_matrix(Tw_2[0:3, 0:3]).as_quat())\n",
    "    pose3 = [Tw_3[0, 3], Tw_3[1, 3], Tw_3[2, 3]] + list(R.from_matrix(Tw_3[0:3, 0:3]).as_quat())\n",
    "    pose4 = [Tw_4[0, 3], Tw_4[1, 3], Tw_4[2, 3]] + list(R.from_matrix(Tw_4[0:3, 0:3]).as_quat())\n",
    "    pose5 = [Tw_5[0, 3], Tw_5[1, 3], Tw_5[2, 3]] + list(R.from_matrix(Tw_5[0:3, 0:3]).as_quat())\n",
    "\n",
    "    posesRobot = [pose1, pose2, pose3, pose4, pose5]\n",
    "\n",
    "    sp = ' '\n",
    "\n",
    "    for i, (x, y, z, qx, qy, qz, qw) in enumerate(posesRobot):\n",
    "        line = \"VERTEX_SE3:QUAT \" + str(i+1) + sp + str(x) + sp + str(y) + sp + str(z) + sp + str(qx) + sp + str(qy) + sp + str(qz) + sp + str(qw) + '\\n'\n",
    "        g2o.write(line)\n",
    "\n",
    "\n",
    "def writeOdom(trans, g2o):\t\n",
    "    sp = ' '\n",
    "    info = '20 0 0 0 0 0 20 0 0 0 0 20 0 0 0 20 0 0 20 0 20'\n",
    "\n",
    "    for i, T in enumerate(trans):\n",
    "        dx, dy, dz = T[0, 3], T[1, 3], T[2, 3]\n",
    "\n",
    "        qx, qy, qz, qw = list(R.from_matrix(T[0:3, 0:3]).as_quat())\n",
    "\n",
    "        line = \"EDGE_SE3:QUAT \" + str(i+1) + sp + str(i+2) + sp + str(dx) + sp + str(dy) + sp + str(dz) + sp + str(qx) + sp + str(qy) + sp + str(qz) + sp + str(qw) + sp +  info + '\\n'\n",
    "\n",
    "        g2o.write(line)\n",
    "\n",
    "\n",
    "def writeCubeVertices(cubes, g2o):\n",
    "    cube1 = cubes[0]\n",
    "\n",
    "    start = [-12, 0, 0, 0]\n",
    "\n",
    "    Tw_1 = np.identity(4)\n",
    "    Tw_1[0, 3], Tw_1[1, 3], Tw_1[2, 3] = start[0], start[1], start[2]\n",
    "    Tw_1[0:3, 0:3] = R.from_euler('z', start[3], degrees=True).as_matrix()\n",
    "\n",
    "    cube = []\n",
    "\n",
    "    for pt in np.hstack((cube1, np.ones((cube1.shape[0], 1)))):\n",
    "        ptWorld = Tw_1 @ pt.reshape(4, 1)\n",
    "\n",
    "        cube.append(ptWorld.squeeze(1)[0:3])\n",
    "\n",
    "    quat = \"0 0 0 1\\n\"\n",
    "    sp = ' '\n",
    "\n",
    "    for i, (x, y, z) in enumerate(cube):\n",
    "        line = \"VERTEX_SE3:QUAT \" + str(i+6) + sp + str(x) + sp + str(y) + sp + str(z) + sp + quat\n",
    "\n",
    "        g2o.write(line)\n",
    "\n",
    "\n",
    "def writeLandmarkEdge(cubes, g2o):\n",
    "    quat = \"0 0 0 1\"\n",
    "    sp = ' '\n",
    "    info = '40 0 0 0 0 0 40 0 0 0 0 40 0 0 0 0.000001 0 0 0.000001 0 0.000001' \n",
    "\n",
    "    for i, cube in enumerate(cubes):\n",
    "        for j, (x, y, z) in enumerate(cube):\n",
    "            line  = \"EDGE_SE3:QUAT \" + str(i+1) + sp + str(j+6) + sp + str(x) + sp + str(y) + sp + str(z) + sp + quat + sp +  info + '\\n'\n",
    "\n",
    "            g2o.write(line)\n",
    "\n",
    "\n",
    "def writeG2o(trans, cubes):\n",
    "    g2o = open(\"noise.g2o\", 'w')\n",
    "\n",
    "    g2o.write('# Robot poses\\n\\n')\n",
    "\n",
    "    writeRobotPose(trans, g2o)\n",
    "\n",
    "    g2o.write(\"\\n # Cube vertices\\n\\n\")\n",
    "\n",
    "    writeCubeVertices(cubes, g2o)\n",
    "\n",
    "    g2o.write('\\n# Odometry edges\\n\\n')\n",
    "\n",
    "    writeOdom(trans, g2o)\n",
    "\n",
    "    g2o.write('\\n# Landmark edges\\n\\n')\n",
    "\n",
    "    writeLandmarkEdge(cubes, g2o)\n",
    "\n",
    "    g2o.write(\"\\nFIX 1\\n\")\n",
    "\n",
    "    g2o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeG2o(trans, noisyCubesLow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing g2o file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize():\n",
    "    cmd = \"g2o -robustKernel Cauchy -robustKernelWidth 1 -o {} -i 50 {} > /dev/null 2>&1\".format(\n",
    "        \"opt.g2o\", \"noise.g2o\")\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading optimized g2o file. And again registering all local point clouds to the first frame using optimized poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readG2o(fileName):\n",
    "    f = open(fileName, 'r')\n",
    "    A = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    poses = []\n",
    "\n",
    "    for line in A:\n",
    "        if \"VERTEX_SE3:QUAT\" in line:\n",
    "            (ver, ind, x, y, z, qx, qy, qz, qw, newline) = line.split(' ')\n",
    "\n",
    "            if int(ind) <= 5:\n",
    "                T = np.identity(4)\n",
    "                T[0, 3], T[1, 3], T[2, 3] = x, y, z\n",
    "                T[0:3, 0:3] = R.from_quat([qx, qy, qz, qw]).as_matrix()\n",
    "\n",
    "                poses.append(T)\n",
    "\n",
    "    poses = np.asarray(poses)\n",
    "\n",
    "    return poses\n",
    "\n",
    "\n",
    "def getRelativeEdge(poses):\n",
    "    T1_2 = np.linalg.inv(poses[0]) @ poses[1]\n",
    "    T2_3 = np.linalg.inv(poses[1]) @ poses[2]\n",
    "    T3_4 = np.linalg.inv(poses[2]) @ poses[3]\n",
    "    T4_5 = np.linalg.inv(poses[3]) @ poses[4]\n",
    "\n",
    "    trans = np.array([T1_2, T2_3, T3_4, T4_5])\n",
    "\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optPoses = readG2o(\"opt.g2o\")\n",
    "optEdges = getRelativeEdge(optPoses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "registerCubes(optEdges, noisyCubesLow)\n",
    "# Here we are just seeing if optimized poses are bringing the original landmark observations \n",
    "# in respective frames closer. However: (read \"TODO3: Results Analysis\" below )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO1: Keep things simple\n",
    "Rewrite the code above as follows:\n",
    "1. We can replicate realistic scenarios as we progress and as need arises. For now, let us keep things _really_ simple (it's ok even if it doesn't make complete sense wrt realistic scenarious, we just want to see tangible results after optimization here): Instead of complicating the above with ICP-SLAM and all, just do the following: optimize for each of the following simple cases:\n",
    "    1. HN-GPI, 0N-RPO, 0N-GLI, 0N-RLO: For **initializing** pose variables, simply add high noise directly to GT instead of using ICP-SLAM. Ensure High Noise (HN) for (Global) Pose variable initialization (GPI), 0 Noise (0N) for Relative Pose Observations (RPO) (basically the edges), 0 Noise for (Global) Landmark Initialization (basically the landmark variables) and (Relative) Landmark Observations (basically the landmarks observed in every local frame).\n",
    "    2. HN-GPI, LN-RPO, 0N-GLI, 0N-RLO: Same as above but LN-RPO (very Low Noise) instead of 0N-RPO.\n",
    "    3. HN-GPI, 0N-RPO, HN-GLI, 0N-RLO: Keep the **initialization** of landmark variables very noisy, just do it manually instead of initializing using say first pose. Ensure the landmark **observations** in every local frame has 0 noise first (and optimize it).\n",
    "    4. HN-GPI, LN-RPO, HN-GLI, LN-RLO: same as 3. but less noise compared to initialization (and optimize it) instead of 0 noise. Notice \"LN-RPO, .., 0N-RLO\" instead of \"0N-RPO, .., 0N-RLO\".\n",
    "\n",
    "Keep information values for both landmark and pose same in all cases.\n",
    "        \n",
    "Note that in 1. and 3. cases, our objective function can in theory reach a minimum of 0 value. \n",
    "\n",
    "### TODO2: Dataset\n",
    "The current code is hardcoded for the 8 point cube dataset at some places. Rewrite it so that it works for slightly more denser dataset:\n",
    "\n",
    "Make the dataset denser. Firstly, add more points to the cube (but in an orderly way, for example at midpoint of every edge). Add another geometry such as sphere. Now optimize it.\n",
    "\n",
    "### TODO3: Results analysis \n",
    "One way to look at whether results have improved is as above (`registerCubes(optEdges, noisyCubesLow)`). However, a better way to do it would be:\n",
    "1. Visualize GT landmarks, initial landmarks and optimized landmarks using 3 different colors.\n",
    "2. Quantitatively, add a simple L2 loss function. Basically, compare between [GT - initial landmark positions] and [GT - optimized landmark positions]. \n",
    "3. Do the above two for poses also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveats\n",
    "\n",
    "1. In this notebook, for easier understanding we treated landmark nodes similar to pose nodes (except that they don't have orientation) as you can see in the `noise.g2o` file. However, G2O of course offers better way to handle landmarks.\n",
    "2. If the ICP-SLAM based formulation taught in class was confusing, note that the goal of this task is just to check if landmark based optimization is working given a noisy initialization. If you want to clear your confusion about ICP-SLAM lecture, read this page: https://www.notion.so/saishubodh/LS-Optimization-in-Vision-and-Robotics-A-Generic-Formulation-19d3172204bf43f988e80a4461e0e75d#b695f0f4cf5e4c4487a2586c7c313e2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
